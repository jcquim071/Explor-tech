{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bienvenue sur la documentation d'EXPLOR.","text":"<ul> <li>Ressources de calcul disponibles</li> <li>Espaces de stockage </li> <li>Applications disponibles</li> <li>Connexion en mode console / en mode graphique</li> <li>Transferts de donn\u00e9es</li> <li>Modules d'environnement</li> <li>Soumission de jobs</li> <li>Quelques bonnes pratiques...</li> <li>FAQ</li> <li>Charte d\u2019utilisation du M\u00e9socentre EXPLOR</li> <li>Formulaires</li> </ul> <p>Pour toute question ou demande d'installation de logiciel veuillez nous contacter : explor-support@univ-lorraine.fr</p>"},{"location":"Gaussian09/","title":"Gaussian","text":""},{"location":"Gaussian09/#example-of-gaussian-job-script-run-a-gaussian-job-for-one-day-using-the-version-gaussian09pgi-with-16-slurm-tasks-requested-and-one-node-ivy","title":"Example of Gaussian Job Script : Run a Gaussian job for one day using the version (Gaussian/09/pgi) with 16 slurm tasks requested and one node ivy","text":"<p>This Example contains two parts:</p> <ul> <li>First one contain example of Gaussian09 input file which includes several options importants such as number of processors for shared memory, and the amount of dynamic memory (kB, MB, and GB)</li> <li>Second one contain example of Gaussian09 job script run for one day with 16 slurm tasks requested and one node ivy</li> </ul>"},{"location":"Gaussian09/#example-of-gaussian-input-file","title":"Example of Gaussian input file:","text":"<p>Note</p> <p>Before submit a gaussian job, you should verify that the number of processors (<code>%NProcShared=16</code>) and the total number of slurm task requested (<code>#SBATCH -n 16</code>) are the same</p> <p>For the memory at Gaussian input file, it depend on the partition:</p> <ul> <li>hf  : 15GB /core or 120GB/node</li> <li>ivy : 3.2GB/core or  50GB/node</li> <li>std : 3.2GB/core or 100GB/node</li> </ul> <p>Its important to know that hf and ivy partitions are better/faster for using Gaussian09</p> <p>Please don't forget to create the checkpoint file</p> <pre><code>%NProcShared=16\n%Mem=\n%Chk=myfile.chk\n# HF 6-31G* OPT\n\nTitle\n\n0 1\nO    x y z\nH    x y z\nH    x y z\n</code></pre>"},{"location":"Gaussian09/#example-of-gaussian09-job-script","title":"Example of Gaussian09 Job Script","text":"<pre><code>#!/bin/bash\n## Partition\n#SBATCH -p ivy\n## Number of nodes\n#SBATCH -N 1\n## Total number of slurm tasks requested\n#SBATCH -n 16\n## Name of a job\n#SBATCH -J NAME\n## Time of a job\n#SBATCH -t 1-00:00:00\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=votremail@univ-lorraine.fr\n\n## Unload all modules\nmodule purge\n## Loads module gaussian/09/pgi\nmodule load gaussian/09/pgi\n\n## Standard input file\nG09COM=myfile.gjf\n## Standard output file\nG09LOG=myfile.log\n## Standard check File\nG09CHK=myfile.chk\n\nhostname\n\n## Set up the temporary directory in $SCRATCHDIR\ncurdir=$PWD\ntmpdir=$SCRATCHDIR/$$\nmkdir -p ${tmpdir}\ncd ${tmpdir}\n\n## Run the program with the working directory\ng09 &lt; $curdir/${G09GJF} &gt; $curdir/${G09LOG}\n\nif [ -e $G09CHK ]; then\n  mv $G09CHK $curdir/\nfi\n</code></pre>"},{"location":"Gaussian09_F/","title":"Gaussian","text":""},{"location":"Gaussian09_F/#exemple-de-script-de-job-en-gaussian-lancer-une-tache-en-gaussian-pendant-une-journee-en-utilisant-la-version-gaussian09pgi-avec-16-taches-de-slurm-demandees-et-un-noeud-ivy","title":"Exemple de script de job en Gaussian : Lancer une tache en gaussian pendant une journee en utilisant la version (Gaussian/09/pgi) avec 16 taches de slurm demandees et un Noeud ivy","text":"<p>Cet exemple comprend deux parties :</p> <ul> <li> <p>Le premier contient un exemple de fichier d'entree de Gaussian09 qui inclut plusieurs options importantes telles que le nombre de processeurs pour la memoire partagee, et la quantite de memoire dynamique (KB, MB, et GB)</p> </li> <li> <p>Le second contient un exemple de script de job Gaussian09 execute pendant une journee avec 16 taches de slurm demandees et un noeud ivy</p> </li> </ul>"},{"location":"Gaussian09_F/#exemple-de-fichier-dentree-input-gaussian","title":"Exemple de fichier d'entree (input) Gaussian :","text":"<p>Note</p> <p>Avant de soumettre un job de Gaussian, vous devez verifier que le nombre de processeurs (%NProcShared=16) et le nombre total de taches de slurm demandees (#SBATCH -n 16) sont les memes     </p> <p>Pour la memoire du fichier d'entree gaussien, cela depend de la partition :</p> <ul> <li>hf  : 15GB /coeur ou 120GB/noeud</li> <li>ivy : 3.2GB/coeur ou  50GB/noeud</li> <li>std : 3.2GB/coeur ou 100GB/noeud</li> </ul> <p>Il est important de savoir que les partitions hf et ivy sont meilleures/plus rapides pour utiliser Gaussian09</p> <p>Veuillez ne pas oublier de creer le fichier checkpoint</p> <pre><code>%NProcShared=16\n%Mem=\n%Chk=myfile.chk\n# HF 6-31G* OPT\n\nTitle\n\n0 1\nO    x y z\nH    x y z\nH    x y z\n</code></pre>"},{"location":"Gaussian09_F/#exemple-de-script-de-job-de-gaussian09","title":"Exemple de script de job de Gaussian09","text":"<pre><code>#!/bin/bash\n## Partition\n#SBATCH -p ivy\n## Nombre de noeuds\n#SBATCH -N 1\n## Nombre de taches demandes\n#SBATCH -n 16\n## Nom du job\n#SBATCH -J NAME\n## Time of a job\n#SBATCH -t 1-00:00:00\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=votremail@univ-lorraine.fr\n\n## Unload all modules\nmodule purge\n## Loads module gaussian/09/pgi\nmodule load gaussian/09/pgi\n\n## Standard input file\nG09COM=myfile.gjf\n## Standard output file\nG09LOG=myfile.log\n## Standard check File\nG09CHK=myfile.chk\n\nhostname\n\n## Set up the temporary directory in $SCRATCHDIR\ncurdir=$PWD\ntmpdir=$SCRATCHDIR/$$\nmkdir -p ${tmpdir}\ncd ${tmpdir}\n\n## Run the program with the working directory\ng09 &lt; $curdir/${G09GJF} &gt; $curdir/${G09LOG}\n\nif [ -e $G09CHK ]; then\n  mv $G09CHK $curdir/\nfi\n</code></pre>"},{"location":"Questions/","title":"Questions Fr\u00e9quentes (FAQ)","text":""},{"location":"Questions/#general","title":"G\u00e9n\u00e9ral","text":"<p>Comment remercier EXPLOR dans mes publications ?</p> <p>En mentionnant l\u2019utilisation d\u2019EXPLOR dans vos communications :</p> <p>*\u00a0Les ressources en calcul ont \u00e9t\u00e9 fournies en partie par le M\u00e9socentre EXPLOR h\u00e9berg\u00e9 par l\u2019Universit\u00e9 de Lorraine\u00a0*</p> <p>*\u00a0High Performance Computing resources were partially provided by the\u00a0EXPLOR centre hosted by the Universit\u00e9 de Lorraine\u00a0*</p> <p>Comment signaler \u00e0 EXPLOR mes publications qui ont utilis\u00e9 ses ressources ?</p> <p>En envoyant une information \u00e0 explor-contact@univ-lorraine.fr ou \u00e0 son Directeur \u00e0 explor-dir@univ-lorraine.fr.</p>"},{"location":"Questions/#connexion","title":"Connexion","text":"<p>Comment se connecter \u00e0 EXPLOR ?</p> <p>Vous pouvez vous connecter \u00e0 votre compte utilisateur EXPLOR en utilisant SSH ou X2GO (-ssh; -x2go)</p> <p>Je n\u2019arrive pas \u00e0 me connecter, qui dois-je contacter ?</p> <p>En cas de probl\u00e8me de connexion, merci d\u2019adresser un mail d\u00e9crivant votre probl\u00e8me \u00e0 explor-support@univ-lorraine.fr.</p> <p>Qu'est-ce que X2Go ?</p> <p>x2go\u00a0est un logiciel qui permet d'acc\u00e9der \u00e0 distance \u00e0 votre frontale d'acc\u00e8s EXPLOR de mani\u00e8re graphique (bureau) via une connexion ssh. Il est disponible en tant que client sous Windows, Linux et MacOS. Pour plus d'informations, vous pouvez vous r\u00e9ferrer au site http://wiki.x2go.org/doku.php/download:start.</p> <p>Comment transf\u00e9rer mes fichiers vers/depuis EXPLOR ?</p> <p>Il existe deux possibilit\u00e9s pour transf\u00e9rer vos donn\u00e9es. Elles sont d\u00e9taill\u00e9es sur la page suivante.</p> <p>Pourquoi ma machine d\u2019acc\u00e8s s\u2019appelle-t-elle <code>vm-XXX</code> ?</p> <p>Afin de garantir la confidentialit\u00e9 des utilisateurs, serveurs virtuels, projets et ressources, les comptes utilisateurs et les projets ont \u00e9t\u00e9 anonymis\u00e9s.</p> <p>Est-ce que j\u2019ai acc\u00e8s \u00e0 internet depuis EXPLOR ?</p> <p>Depuis votre environnement de travail (frontale d'acc\u00e8s), vous avez acc\u00e8s \u00e0 internet. Par contre, les n\u0153uds de calcul ne peuvent communiquer avec l'ext\u00e9rieur d'EXPLOR.</p> <p>Je suis rattach\u00e9 \u00e0 deux projets, pourquoi mes param\u00e8tres de connexion sont-ils diff\u00e9rents ?</p> <p>Chaque projet dispose de son environnement propre (et anonymis\u00e9), accessible via une machine virtuelle d\u00e9di\u00e9e (frontale d'acc\u00e8s). Les param\u00e8tres de connexion sont donc diff\u00e9rents pour chaque projet.</p> <p>Je suis rattach\u00e9 \u00e0 deux projets, comment puis-je transf\u00e8rer mes donn\u00e9es d\u2019un projet \u00e0 l\u2019autre ?</p> <p>Les proc\u00e9dures relatives au transfert de donn\u00e9es entre deux projets sont expliqu\u00e9es \u00e0 la page suivante.</p> <p>Comment utiliser les serveurs que j\u2019ai achet\u00e9s depuis mon projet ?</p> <p>Un mode op\u00e9ratoire vous sera adress\u00e9 \u00e0 l'installation de vos serveurs qui vous expliquera comment acc\u00e9der \u00e0 vos serveurs sous SLURM.</p>"},{"location":"Questions/#utilisation-des-ressources","title":"Utilisation des ressources","text":"<p>Comment soumettre un job ?</p> <p>Depuis votre environnement, vous pourrez utiliser le gestionnaire de travaux SLURM pour soumettre vos travaux. Merci de consulter la documentation mis \u00e0 votre disposition \u00e0 Soumission de job. </p> <p>Comment se connecter en interactif sur un n\u0153ud de calcul ?</p> <p>Par une r\u00e9servation du n\u0153ud \u00e0 travers la commande\u00a0salloc Par exemple, si vous voulez demander un n\u0153ud de la partition std pendant 1 heure taper\u00a0:  salloc -N1 -p std -t 1\u00a0: 00\u00a0: 00 srun \u2013pty bash</p> <p>Quelle partition choisir ? </p> <p>En fonction du type de travaux et de vos besoins en ressources (CPU, m\u00e9moire, GPU, etc), vous serez amen\u00e9 \u00e0 pr\u00e9f\u00e9rer une partition ou une autre. L'ensemble des partitions est d\u00e9crit \u00e0 la page: Ressources de calcul disponibles.</p> <p>De mani\u00e8re g\u00e9n\u00e9rale\u00a0: </p> <ul> <li>la partition hf est r\u00e9serv\u00e9e aux travaux s\u00e9quentielles ou peu parall\u00e8les (1 \u00e0 8 c\u0153urs maximum). </li> <li>les partitions std et sky donnent acc\u00e8s \u00e0 des n\u0153uds de 32 c\u0153urs reli\u00e9s par un r\u00e9seau basse latence et sont adapt\u00e9s aux travaux parall\u00e8les (de 32 \u00e0 1024 c\u0153urs). </li> <li>les partitions p100 et gtx sont adapt\u00e9s aux travaux n\u00e9cessitant des GPUs.</li> </ul> <p>En cas de doute, vous pouvez envoyer un mail au support \u00e0 l\u2019adresse explor-support@univ-lorraine.fr.</p> <p>Quel temps de calcul dois-je indiquer dans mon script ?</p> <p>Le temps de calcul maximal qui peut vous \u00eatre allou\u00e9 d\u00e9pend de la partition et du nombre de n\u0153uds que vous choississez. </p> <p>Voir Ressources de calcul disponibles. </p> <p>Nous vous conseillons de sp\u00e9cifier au mieux votre demande afin de permettre au gestionnaire SLURM d'optimiser l'utilisation des ressources.</p> <p>Le job que j'ai soumis n'a pas d\u00e9marr\u00e9, il reste dans la file d'attente. Pourquoi\u00a0? </p> <p>La commande squeue va vous donner le statut de votre job (derni\u00e8re colonne \u00ab\u00a0REASON\u00a0\u00bb). Votre job en attente peut \u00eatre\u00a0en statut\u00a0:</p> <ul> <li>Ressources\u00a0: votre job va bient\u00f4t d\u00e9marrer, SLURM est en train de r\u00e9server la ressource n\u00e9cessaire \u00e0 son ex\u00e9cution</li> <li>Priority\u00a0: un ou plusieurs autres job sont avant vous dans la file d'attente</li> <li>QOSGrpJobsLimit\u00a0: des limites sont associ\u00e9s \u00e0 chaque partition, projet ou utilisateur en fonction des ressources demand\u00e9es. </li> </ul> <p>Ces limites sont d\u00e9finies \u00e0 la page suivante. </p> <p>Votre job changera de statut lorsque ces limites ne seront plus atteintes.</p> <p>Le job que j'ai soumis est en attente, quand va-t-il d\u00e9marrer\u00a0?</p> <p>L'option <code>--start</code> de la commande squeue peut vous donner une estimation de l'heure \u00e0 laquelle SLURM pense que votre job d\u00e9marrera.</p> <p>A la soumission de mon job, j'ai\u00a0l'erreur suivante\u00a0: Could not select QOS, please verify resources selected ? </p> <p>Dans votre fichier de soumission SLURM, les param\u00e8tres que vous avez sp\u00e9cifi\u00e9s (partition, nombre de n\u0153uds, temps de calcul, etc.) sont incorrects. </p> <p>Vous pouvez consulter la documentation technique Ressources de calcul et soumission de job pour v\u00e9rifier la compatibilit\u00e9 de vos param\u00e8tres.</p> <p>sbatch: error: Batch job submission failed: Invalid qos specification ? </p> <p><code>Invalid qos specification</code> signifie que vous avez demand\u00e9 une ressource \u00e0 laquelle vous n\u2019avez pas acc\u00e8s. </p> <p>Pour plus d'informations, vous pouvez visiter la page suivante.</p> <p>A quoi sert la commande module ? </p> <p>La commande module permet de charger dans l'environnement utilisateur des logiciels, des compilateurs, etc. Pour plus d'informations sur l'utilisation de la commande module, vous pouvez vous r\u00e9ferrer \u00e0 la page suivante. </p> <p>Est-ce que python est install\u00e9 dans EXPLOR ? </p> <p>Plusieurs versions de python sont install\u00e9es dans EXPLOR. Elles sont accessibles via la commande 'module'\u00a0:</p> <ul> <li>python2 via la commande <code>module load anaconda/2</code></li> <li>python3 via la commande <code>module load anaconda/3</code></li> <li>les versions sp\u00e9cifiques optimis\u00e9es par Intel, via les commandes <code>module load python/versionX/intel</code></li> </ul> <p>Mon logiciel a besoin de ressources GPU, comment puis-je sp\u00e9cifier ce besoin \u00e0 SLURM ? </p> <p>Dans votre script de soumission, il faut tout d'abord choisir une partition poss\u00e9dant des GPUs p100, gtx ou k20, puis pr\u00e9ciser le nombre de GPUs requis en renseignant l'option \u2013gres de la commande sbatch (ex.\u00a0: --gres=gpu:2 pour demande 2 GPUs).</p>"},{"location":"applications/","title":"Compilateurs disponibles","text":"Compilateurs Version Intel Parallel Studio XE Cluster Edition 2017  2018  2019 PGI Community Edition 2017 GCC 4.9.4  5.4.0  6.3.0  7.1.0  9.2.0  11.2  12.2  13.2 Cuda 6.5  7.0  7.5  8.0  9.0  9.1  9.2 10.1"},{"location":"applications/#mpi-message-passing-interface-disponibles","title":"MPI (Message Passing Interface) disponibles","text":"MPI Version Intelmpi 2017  2018  2019 Openmpi 2.1.x  3.0.x  4.0.x"},{"location":"applications/#libraries-disponibles","title":"Libraries disponibles","text":"MPI Version atlas 3.10.3 boost 1.64.0 fftw 3.3.7  3.3.8 hdf5 1.10.1 hypre 2.10.0b  2.11.2 metis 4.0.3 mkl 2017  2018  2019 nfft 3.4.0 plumed 2.3.1"},{"location":"applications/#applications-disponibles","title":"Applications disponibles","text":"Applications Version GPU Compatible Abinit 8.10.2  9.10.3 GPU Abaqus* 2017 Amber* 16  22 GPU Ansys Fluent* 17.2  18.0  22.1 Caffe 1.0  2.0 GPU CASTEP* 16.1 Cp2k 4.1  6.1 Crystal* 14 Firefox 65 Foam-extend 4.0 FDS 6.7.0 FEFF 9.0 FreeFem++ 3.60  3.62  4.11  4.14 Gaussian* 03  09 Gromacs 5.1.4  2016.3  2022.3  2023.2 HyperWorks Solvers* 2017.2.1 Lammps 2017  2018  2020  2022 Matlab* r2017b  2019b Mothur 1.40.5 OpenFOAM 2.2.2  4.1  5.0  7.0 Pytorch 1.0 GPU Quantum Espresso* 5.3.0  6.0  7.1  7.2 R 3.5.2  4.1.3 Siesta 4.0.1  4.1.5 TeraChem* 1.9 Uspex 9.4.4 VASP* 5.4.1   5.4.4 <p>*Une preuve d'achat de licence vous sera demandee pour pouvoir utiliser ces applications.</p>"},{"location":"applications/#applications-graphiques","title":"Applications graphiques","text":"Applications Version Avogadro 1.90.0 Ansys 18.0 GaussView 5.0.9 Gnuplot 4.6 Grace Matlab r2017b  r2019b Paraview 4.4.0   5.0.1"},{"location":"applications/#outils","title":"Outils","text":"Outils Version advisor 2018  2019 anaconda 2.5.1  3.5.1 cmake 3.10.2  3.15.5 git 2.15.1 gmsh 3.0.6 idb 2018 inspector 2018  2019 libtool 2.4.6 paraview 4.4.0  5.0.1 python 2.7  3.6 tbb 2018  2019 vtune-amp 2018  2019"},{"location":"bp/","title":"Quelques bonnes pratiques :","text":"<ul> <li>Fermer si possible les applications graphiques lourdes avant votre d\u00e9connexion de X2GO.</li> <li>Compiler vos applications avec les bonnes options de vectorisation (AVX) et instructions. Les partitions std et hf supporte AVX2, les partitions ivy et k20 supporte AVX.</li> <li>Sp\u00e9cifier une estimation correcte du temps de calcul de votre job, une dur\u00e9e de job correctement estim\u00e9e permet de fluidifier l'ex\u00e9cution des jobs.</li> </ul>"},{"location":"chartes/","title":"Charte d\u2019utilisation du M\u00e9socentre EXPLOR","text":"<ul> <li>version PDF</li> </ul>"},{"location":"chartes/#mention-de-lutilisation-dexplor-dans-les-articles-les-communications-etc","title":"Mention de l\u2019utilisation d\u2019EXPLOR dans les articles, les communications, etc:","text":"<p>Version Fran\u00e7aise:</p> <ul> <li>Les ressources en calcul ont \u00e9t\u00e9 fournies en partie par le M\u00e9socentre EXPLOR h\u00e9berg\u00e9 par l\u2019Universit\u00e9 de Lorraine</li> </ul> <p>English version:</p> <ul> <li>High Performance Computing resources were partially provided by the EXPLOR centre hosted by the University de Lorraine</li> </ul>"},{"location":"console/","title":"Se connecter depuis un terminal unix","text":"<ul> <li> <p>Pour vous connecter \u00e0 votre environnement de travail EXPLOR, lancez depuis le terminal :</p> <p><code>$ ssh -p votre_port_de_connexion votre_identifiant@193.54.9.82</code></p> </li> </ul> <p>Afin d'\u00e9viter de devoir sp\u00e9cifier le port de connexion \u00e0 chaque commande <code>ssh</code>,<code>scp</code>,<code>rsync</code>,... nous recommandons l'utilisation d'un alias SSH</p>"},{"location":"console/#creation-dun-alias-ssh","title":"Cr\u00e9ation d'un alias SSH","text":"<ul> <li>Cr\u00e9er un fichier <code>~/.ssh/config</code>  sur votre poste personnel et \u00e9diter le</li> </ul> <pre><code>Host meso-explor\n    HostName 193.54.9.82\n    Port votre_port_de_connexion\n    User votre_identifiant\n</code></pre> <ul> <li> <p>Modifier les droits du fichier :</p> <p><code>$ chmod 644 ~/.ssh/config</code></p> </li> <li> <p>Vous pouvez maintenant vous connecter au m\u00e9socentre avec la commande suivante :</p> <p><code>$ ssh meso-explor</code></p> </li> <li> <p>Pour copier un dossier depuis votre poste de travail sur votre environnement de travail EXPLOR vous pouvez alors utiliser la commande :</p> <p><code>$ scp -r dossier_posteperso meso-explor:.</code></p> </li> <li> <p>au lieu de </p> <p><code>$ scp -r -P votre_port_de_connexion dossier_posteperso votre_identifiant@193.54.9.82:.</code></p> </li> </ul>"},{"location":"console/#modifier-le-mot-de-passe-par-defaut","title":"Modifier le mot de passe par d\u00e9faut","text":"<p>Pour modifier le mot de passe lancer la commande :</p> <pre><code>$ passwd\n</code></pre> <p>Merci de modifier votre mot de passe \u00e0 votre premi\u00e8re connexion</p>"},{"location":"console/#connexion-sans-mot-de-passe","title":"Connexion sans mot de passe","text":"<p>Apr\u00e8s avoir modifi\u00e9 votre mot de passe, vous pouvez \u00e9galement opter pour une connexion sans mot de passe \u00e0 l'aide d'une cl\u00e9 d'authentification. </p> <ul> <li> <p>Depuis votre poste de travail personnel lancer la commande :</p> <p><code>$ ssh-keygen -t rsa</code></p> </li> <li> <p>appuyer deux fois sur entr\u00e9e.</p> </li> <li> <p>Copier la cl\u00e9 publique g\u00e9n\u00e9r\u00e9e sur votre environnement EXPLOR :</p> <p><code>$ scp ~/.ssh/id_rsa.pub meso-explor:.ssh/authorized_keys</code></p> </li> </ul> <p>Vous pouvez maintenant vous connecter depuis votre poste personnel sans entrer mot de passe.</p>"},{"location":"formulaires/","title":"Formulaires","text":""},{"location":"formulaires/#trames-pour-depots-de-projets","title":"Trames pour d\u00e9p\u00f4ts de projets","text":"<ul> <li>version Word</li> <li>version LaTeX</li> </ul>"},{"location":"graphique/","title":"En mode graphique","text":"<p>La connexion \u00e0 votre environnement EXPLOR en mode graphique n\u00e9cessite le client X2GO. Ce programme est compatible windows, mac os et linux.</p> <p>Vous pouvez t\u00e9l\u00e9charger le client X2GO sur la page suivante : http://wiki.x2go.org/doku.php/download:start ou dans les d\u00e9p\u00f4ts de la plupart des distributions linux.</p>"},{"location":"graphique/#configuration-de-x2go","title":"Configuration de X2GO","text":"<p>Dans \"Session\" :</p> <ul> <li> <p>\"H\u00f4te\" : 193.54.9.82</p> </li> <li> <p>\"Identifiant\" : votre_identifiant</p> </li> <li> <p>\"Port\" : votre_port_de_connexion</p> </li> <li> <p>(Facultatif) S\u00e9lectionner voter cl\u00e9 priv\u00e9e</p> </li> <li> <p>\"Type de session\" : XFCE</p> </li> </ul> <p></p> <p>Dans \"Media\" :</p> <ul> <li>D\u00e9cochez la prise en charge du son</li> </ul> <p></p> <ul> <li>Cliquer sur OK puis connectez-vous \u00e0 la session</li> </ul> <p></p> <p>Vous voici sur votre bureau personnel EXPLOR !</p>"},{"location":"graphique/#se-deconnecter-de-votre-session-x2go","title":"Se d\u00e9connecter de votre session X2GO","text":"<p>Pour vous d\u00e9connecter, il suffit simplement de fermer la fen\u00eatre de votre session X2GO. Vos fen\u00eatres et applications ouvertes seront conserv\u00e9es jusqu'\u00e0 la prochaine connexion.</p> <p>Afin de limiter les ressources syst\u00e8mes pouvant entra\u00eener des ralentissements dans votre environnement de travail partag\u00e9, nous vous demandons d'utiliser avec parcimonie les applications lourdes en ressources syst\u00e8mes telles que firefox et de fermer celles-ci avant de vous d\u00e9connecter de votre session.</p>"},{"location":"materiel/","title":"Ressources de calcul","text":""},{"location":"materiel/#description-des-ressources-de-calcul-disponibles","title":"Description des ressources de calcul disponibles","text":""},{"location":"materiel/#materiel-explor","title":"Mat\u00e9riel EXPLOR","text":"Partition Node-id Mat\u00e9riel CPU GPU # de n\u0153ud # de c\u0153urs / n\u0153ud # de c\u0153urs total M\u00e9moire dispo / n\u0153ud M\u00e9moire par d\u00e9faut / c\u0153ur R\u00e9seau Mode Exclusif Tflops Total (DP) std cn(a/b)[01-64] DELL C6320 Intel Xeon E5-2683v4 2.1 GHz, AVX2 n/a 128 32 4096 120GB 3750MB Omnipath 100Gb/s Non 137.6 std cnc[01-48] DELL C6420 Intel Xeon Gold 6130 Processor 2.1 GHz, AVX512 n/a 48 32 1536 180GB 5625MB Omnipath 100Gb/s Non 63.9 std cnd[01-12] DELL C6220 Intel Xeon E5-2640v2 2.0 GHz, AVX n/a 12 16 192 60GB 3750MB Infiniband 40Gb/s Non 3.1 std cne[01-16] DELL R630 Intel Xeon E5-2637v4 3.5 GHz, AVX2 n/a 16 8 128 120GB 15000MB Ethernet 100Gb/s Non 7.2 std cni[25-28] Dell C6420 [Intel Xeon Gold 6230 2.1 GHz, AVX512] (https://ark.intel.com/content/www/fr/fr/ark/products/192437/intel-xeon-gold-6230-processor-27-5m-cache-2-10-ghz) n/a 40 4 160 180GB 4500MB Infiniband 100Gb/s Non 7.2 std cnl[01] Dell R6615 [AMD EPYC 9254 2.9 GHz, AVX2] (https://www.amd.com/fr/products/cpu/amd-epyc-9254) n/a 24 1 24 240GB 10000MB Infiniband 100Gb/s Non 7.2 gpu gpb[01-06] DELL C4130 Intel Xeon E5-2683v4 2.1 GHz, AVX NVIDIA Tesla P100 6  4xGPU/n\u0153ud 32 192 120GB 3750MB Omnipath 100Gb/s Non 119.3 gpu gpc[01-04] DELL T630 Intel Xeon E5-2683v4 2.1 GHz, AVX GEFORCE GTX 1080 Ti 4  2xGPU/n\u0153ud 32 128 120GB 3750MB Omnipath 100Gb/s Non 6.9"},{"location":"materiel/#materiel-heberge","title":"Mat\u00e9riel H\u00e9berg\u00e9","text":"<p>Le m\u00e9socentre a \u00e9galement vocation a h\u00e9berger du mat\u00e9riel. Contactez-nous  explor-contact@univ-lorraine.fr pour toute demande d'informations compl\u00e9mentaires concernant l'h\u00e9bergement de mat\u00e9riel.</p> Partition Mat\u00e9riel CPU GPU # de n\u0153ud # de c\u0153urs / n\u0153ud # de c\u0153urs total M\u00e9moire dispo / n\u0153ud M\u00e9moire par d\u00e9faut / c\u0153ur R\u00e9seau Mode Exclusif Tflops Total mysky DELL C6420 Intel Xeon Gold 6130 Processor 2.1 Ghz, AVX512 n/a 16 32 512 153.6GB 4.80GB Omnipath 100Gb/s Non 19.2 ------------- -------------- ----- ----- ----------- --------------------- ----------------------- ----------------------------- --------------------------- ----------------- --------------- -------------- myhf DELL C6420 Intel Xeon Gold 5122 Processor 3.6 Ghz, AVX2 n/a 8 8 64 96GB 1.50GB Omnipath 100Gb/s Non 11.3 ------------- -------------- ----- ----- ----------- --------------------- ----------------------- ----------------------------- --------------------------- ----------------- --------------- -------------- mycas DELL C6820 Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz, AVX512 n/a 12 40 480 180GB 4.50GB Omnipath 100Gb/s Non 80.6 ------------- -------------- ----- ----- ----------- --------------------- ----------------------- ----------------------------- --------------------------- ----------------- --------------- -------------- mylhf DELL R640 Intel Xeon Gold 5222 Processor 3.8 Ghz, AVX512 n/a 2 8 16 7465GB 93.25GB Omnipath 100Gb/s Non 1.0 myt4 DELL R740 Intel(R) Xeon(R) Gold 6126 CPU @ 2.60GHz, AVX TESLA T4 3  3xGPU/n\u0153ud 32 96 84GB 3500MB Omnipath 100Gb/s Non 11.3 <p>Processeurs Intel Skylake (6\u00e8me g\u00e9n\u00e9ration) :</p> <p>Les n\u0153uds \"skylake\" (cnc[01-64] et cnf[01-08]) comprend 72 n\u0153uds connect\u00e9s en r\u00e9seau 100Gb \u00e0 basse-latence, chaque n\u0153ud disposant de deux processeurs de type Skylake Intel Xeon Gold 6130 Processor (chacun comprenant 16 c\u0153urs cadenc\u00e9s \u00e0 2.10Ghz, soit 32 c\u0153urs par n\u0153uds) et 192 Go de RAM. Elle est adapt\u00e9e aux applications massivement parall\u00e8les.</p> <p>La seule v\u00e9ritable diff\u00e9rence entre les processeurs Skylake (6\u00e8me g\u00e9n\u00e9ration) et Broadwell (5\u00e8me g\u00e9n\u00e9ration) est que les premiers poss\u00e8dent des instructions de calcul plus efficaces. Donc ils sont capables de g\u00e9n\u00e9rer plus d'op\u00e9rations par secondes (flops) que les Broadwell a une seule condition de recompiler les programmes avec les bonnes options pour permettre d'utiliser ces nouveaux registres (AVX512).</p> <p>Processeurs Intel Broadwell (5\u00e8me g\u00e9n\u00e9ration) :</p> <p>Les n\u0153uds \"standard\" (cn(a/b)[01-64])  comprend 128 n\u0153uds connect\u00e9s en r\u00e9seau 100Gb \u00e0 basse-latence, chaque n\u0153ud disposant de deux processeurs de type Broadwell Intel Xeon E5-2683 v4 (chacun comprenant 16 c\u0153urs cadenc\u00e9s \u00e0 2.10Ghz, soit 32 c\u0153urs par n\u0153uds) et 128 Go de RAM. Elle est adapt\u00e9e aux applications massivement parall\u00e8les.</p> <p>Les n\u0153uds \"haute frecuence\"(cne[01-16]) comprend 16 n\u0153uds connect\u00e9s en r\u00e9seau 10Gb ethernet, chaque n\u0153ud disposant de deux processeurs Intel Xeon E5-2637 v4 chacun comprenant 4 c\u0153urs cadenc\u00e9s \u00e0 3.5Ghz et 128 Go de RAM. Elle est adapt\u00e9e aux applications s\u00e9rielles ou faiblement parall\u00e9lis\u00e9es.</p> <p>Les n\u0153uds gpu gpb[01-06] comprend 6 n\u0153uds connect\u00e9s en reseau 100Gb \u00e0 basse-latence , chaque n\u0153ud diposant de deux processeurs de type Broadwell Intel Xeon E5-2683 v4 (chacun comprenant 16 c\u0153urs cadenc\u00e9s \u00e0 2.10Ghz, soit 32 c\u0153urs par n\u0153uds), 128 Go de RAM et de 4 cartes NVIDIA Tesla P100.</p> <p>Les n\u0153uds gou \"GTX\" gpc[01-04] comprend 4 n\u0153uds connect\u00e9s en reseau 100Gb \u00e0 basse-latence , chaque n\u0153ud diposant de deux processeurs de type Broadwell Intel Xeon E5-2683 v4 (chacun comprenant 16 c\u0153urs cadenc\u00e9s \u00e0 2.10Ghz, soit 32 c\u0153urs par n\u0153uds), 128 Go de RAM et de 2 cartes GEFORCE GTX 1080 Ti</p> <p>Processeurs Intel de Ivy Bridge (3\u00e8me g\u00e9n\u00e9ration) :</p> <p>Les n\u0153uds cndi[01-12] comprend 12 n\u0153uds connect\u00e9s en r\u00e9seau Infiniband 40Gb \u00e0 basse-latence, chaque n\u0153ud disposant de deux processeurs Intel Xeon E5-2640v2 2.0 GHz chacun comprenant 8 c\u0153urs cadenc\u00e9s \u00e0 2.0 Ghz et 64 Go de RAM. Elle est adapt\u00e9e aux applications parall\u00e8les.</p>"},{"location":"materiel/#limitations-en-duree-et-en-ressources-dun-job","title":"Limitations en dur\u00e9e et en ressources d'un job","text":"<p>Les limitations suivantes en terme de ressources et de dur\u00e9es sont appliqu\u00e9es au m\u00e9socentre pour chaque job soumis :</p> Partition # Max de N\u0153uds / job # Max de C\u0153urs / job Dur\u00e9e Maximale /job (jours) # Max de GPU / job # Max de jobs actifs std 1  2  4  8  16  32 32  64  128  256  512  1024 16  16  8  4  4  2 -  -  -  -  -  - 32  16  16  8  4  2 hf 1 8 16 - - ivy 12 192 16 - - sky 1  2  4  8  16 32  64  128  256  512 16  16  8  4  4 - 16  8  8  4  2 p100 1  2  3 32  64  96 16  8  4 4  8  12 -  -  - GTX 1  2 32  64 16  8 2  4 -  -"},{"location":"materiel/#limitations-en-ressources-dun-utilisateur","title":"Limitations en ressources d'un utilisateur","text":"<p>Les limitations suivantes en terme de ressources (N\u0153uds, CPU, GPU)  pour chaque utilisateur :</p> Partition # Max de N\u0153uds / utilisateur # Max de CPU / utilisateur # Max de GPU / utilisateur std 32 1024 - hf - 64 - ivy 12 192 - sky 24 768 - p100 - 96 12 GTX - 64 4 <p>La soumission du job sera refus\u00e9e si la dur\u00e9e maximale n'est pas sp\u00e9cifi\u00e9e ou si les ressources demand\u00e9es d\u00e9passent les limitations ci-dessus.</p>"},{"location":"module/","title":"Les Modules","text":"<p>Les modules sont des fichiers de configuration qui contiennent des instructions afin de modifier votre environnement logiciel. Un fichier module contient les informations n\u00e9cessaires pour rendre disponible une application ou une biblioth\u00e8que dans la session de l'utilisateur.</p> <p>Les modules sont g\u00e9r\u00e9s par le logiciel Lmod 7.4.</p>"},{"location":"module/#lister-les-modules-installes","title":"Lister les modules install\u00e9s","text":"<p>La commande <code>$ module available</code> ou  <code>$ module av</code> ou bien encore <code>$ ml av</code> liste les modules actuellement disponibles.</p> <pre><code>[dpena@vm-gce17 gce17]$ module available\n\n--------------------------------------------- /opt/modulefiles/compilers ----------------------------------------------\n   gcc/4.9.4 (D)    gcc/5.4.0    gcc/6.3.0    intel/2017.1.132    pgi/16.10\n\n------------------------------------------------ /opt/modulefiles/mpi -------------------------------------------------\n   intelmpi/2017.1.132    openmpi/2.1.0/gcc-4.9.4 (D)    openmpi/2.1.0/intel17    openmpi/2.1.0/pgi-16\n\n--------------------------------------------- /opt/modulefiles/libraries ----------------------------------------------\n   hypre/2.10.0b    metis/4.0.3    mkl/2017.1.132\n\n------------------------------------------------ /opt/modulefiles/apps ------------------------------------------------\n   quantum-espresso/5.3.0/intel17    quantum-espresso/6.0/intel17    vasp/5.4.1/intel17\n\n----------------------------------------------- /opt/modulefiles/tools ------------------------------------------------\n   advisor/2017.1.1.486553    idb/2017    inspector/2017.1.1.484836    vtune-amp/2017.1.0.486011\n\n  O\u00f9:\n   D:  Default Module\n\nUtilisez \"module spider\" pour trouver tous les modules possibles.\nUtilisez \"module keyword key1 key2 ...\" pour chercher tous les modules possibles qui correspondent \u00e0 l'une des cl\u00e9s\n(key1, key2).\n</code></pre>"},{"location":"module/#operations-sur-les-modules","title":"Op\u00e9rations sur les modules","text":""},{"location":"module/#charger-un-module","title":"Charger un module","text":"<p>Pour charger un module, par exemple le compilateur gcc dans sa version 6.9.3 il suffit de lancer la commande :</p> <pre><code>$ module load gcc/6.3.0\n</code></pre> <p>Pour charger le compilateur intel, les librairies MPI intel et mkl lancer la commande :</p> <pre><code>$ module load intel intelmpi mkl\n</code></pre> <p>Vous pouvez rajouter une commande module load  dans votre <code>~/.bashrc</code>. Les modules seront alors automatiquement charg\u00e9s \u00e0 votre connexion.</p>"},{"location":"module/#decharger-un-module","title":"D\u00e9charger un module","text":"<p>Pour enlever un module de votre environnement, par exemple le module <code>gcc/6.3.0</code> lancer la commande :</p> <pre><code>$ module unload gcc/6.3.0\n</code></pre>"},{"location":"module/#decharger-tous-les-modules","title":"D\u00e9charger tous les modules","text":"<p>Pour d\u00e9charger tous les modules de votre environnement lancer la commande :</p> <pre><code>$ module purge\n</code></pre>"},{"location":"module/#lister-les-modules-charges","title":"Lister les modules charg\u00e9s","text":"<p>Pour lister les modules actuellement charg\u00e9s lancer la commande <code>$ module list</code> :</p> <pre><code>[dpena@vm-gce17 gce17]$ module list\n\nCurrently Loaded Modules:\n  1) intel/2017.1.132      3) mkl/2017.1.132   5) hypre/2.10.0b\n  2) intelmpi/2017.1.132   4) metis/4.0.3      6) advisor/2017.1.1.486553\n</code></pre>"},{"location":"slurm/","title":"Slurm","text":"<p>SLURM est un job scheduler. Son r\u00f4le est de g\u00e9rer la file d'attente et de lancer les calculs lorsque les ressources demand\u00e9es sont disponibles.</p>"},{"location":"slurm/#les-partitions","title":"Les partitions","text":"<p>Les diff\u00e9rents n\u0153uds de calcul sont regroup\u00e9s selon des partitions. Lors de la soumission d'un job, il faut choisir une partition.</p> <p>Les partitions \u00e0 disposition sont les suivantes :</p> <ul> <li>std : Les n\u0153uds standard en r\u00e9seau basse latence Intel Omnipath 100GB/s.</li> <li>hf  : Les n\u0153uds hautes-fr\u00e9quences en r\u00e9seau 10GB/s.</li> <li>ivy : Les n\u0153uds g\u00e9n\u00e9ration Ivy-Bridge en r\u00e9seau Infiniband 40GB/s</li> <li>k20 : Les n\u0153uds GPU Tesla K20m</li> </ul> <p>Pour lister les partitions tapez la commande <code>$ sinfo</code></p> <pre><code>[cal01@vm-support01 explor-support]$ sinfo\nPARTITION AVAIL    AVAIL_FEATURES   NODES   NODES(A/I/O/T) NODELIST\nstd          up BROADWELL,INTEL,H      16        1/15/0/16 cne[01-16]\nstd          up SKYLAKE,OPA,INTEL       8          1/7/0/8 cnf[01-08]\nstd          up CASCADELAKE,OPA,I       2          0/2/0/2 cnh[01-02]\nstd          up CASCADELAKE,IB,IN      28        5/23/0/28 cni[01-24,29-32]\nstd          up CASCADELAKE,IB,IN       8          0/8/0/8 cnk[01-08]\nstd          up      EPYC4,IB,AMD       2          0/2/0/2 cnl[02-03]\nstd          up SKYLAKE,OPA,INTEL      48       31/17/0/48 cnc[01-48]\nstd          up SKYLAKE,OPA,INTEL      12         3/9/0/12 cnc[53-64]\nstd          up IVY,IB,INTEL,NOPR      12         8/4/0/12 cnd[01-12]\nstd          up CASCADELAKE,OPA,I      12        2/10/0/12 cng[01-12]\nstd          up CASCADELAKE,IB,IN       4          3/1/0/4 cni[25-28]\nstd          up EPYC3,IB,AMD,NOPR      64       47/17/0/64 cnj[01-64]\nstd          up EPYC4,IB,AMD,NOPR       1          1/0/0/1 cnl01\nstd          up BROADWELL,OPA,INT     121     107/10/4/121 cna[02-17,19-39,41-64],cnb[01-08,10-12,14-52,54-55,57-64]\ngpu          up CASCADELAKE,IB,RT       2          1/1/0/2 gpe[01-02]\ngpu          up CASCADELAKE,L40,I       1          0/1/0/1 gpf01\ngpu          up BROADWELL,OPA,P10       6          6/0/0/6 gpb[01-06]\ngpu          up BROADWELL,OPA,GTX       4          3/1/0/4 gpc[01-04]\ngpu          up CASCADELAKE,OPA,T       3          3/0/0/3 gpd[01-03]\n(A/I/O/T): (allocated/idle/other/total)\n</code></pre>"},{"location":"slurm/#lister-les-jobs-soumis","title":"Lister les jobs soumis","text":"<p>Pour lister les jobs soumis taper la commande <code>$ squeue</code></p> <pre><code>[dpena@vm-gce17 ~]$ squeue \n             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n              5220        hf PingPong    dpena PD       0:00      2 (Resources)\n              5221        hf PingPong    dpena PD       0:00      2 (Priority)\n              5222        hf PingPong    dpena PD       0:00      2 (Priority)\n              5223        hf PingPong    dpena PD       0:00      2 (Priority)\n              5224        hf PingPong    dpena PD       0:00      2 (Priority)\n              5225        hf PingPong    dpena PD       0:00      2 (Priority)\n              5226        hf PingPong    dpena PD       0:00      2 (Priority)\n              5227        hf PingPong    dpena PD       0:00      2 (Priority)\n              5228        hf PingPong    dpena PD       0:00      2 (Priority)\n              5229        hf PingPong    dpena PD       0:00      2 (Priority)\n              5230        hf PingPong    dpena PD       0:00      2 (Priority)\n              5231        hf PingPong    dpena PD       0:00      2 (Priority)\n              5212        hf PingPong    dpena  R       0:06      2 cne[01-02]\n              5213        hf PingPong    dpena  R       0:06      2 cne[03-04]\n              5214        hf PingPong    dpena  R       0:05      2 cne[05-06]\n              5215        hf PingPong    dpena  R       0:03      2 cne[07-08]\n              5216        hf PingPong    dpena  R       0:03      2 cne[09-10]\n              5217        hf PingPong    dpena  R       0:03      2 cne[11-12]\n              5218        hf PingPong    dpena  R       0:03      2 cne[13-14]\n              5219        hf PingPong    dpena  R       0:03      2 cne[15-16]\n</code></pre> <p>en mode graphique, vous pouvez \u00e9galement taper la commande <code>$ sview</code>.</p>"},{"location":"slurm/#soumission-dun-job","title":"Soumission d'un job","text":"<p>Pour soumettre un job lancer la commande :</p> <pre><code>$ sbatch script.slurm\n</code></pre> <p>Avant de soumettre un job vous devez au pr\u00e9alable charger les modules n\u00e9cessaires.</p> <p>Quelques exemples de scripts de soumission :</p>"},{"location":"slurm/#exemple-calcul-de-3-jours-mono-processeur","title":"Exemple : calcul de 3 jours  mono-processeur","text":"<pre><code>#!/bin/bash\n## Partition\n#SBATCH -p std\n## Nombre de noeuds\n#SBATCH -N 1  \n## Nom du job\n#SBATCH -J mono-proc\n## Nombre de taches demand\u00e9s\n#SBATCH -n 1\n#SBATCH -t 3-00:00:00\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=votremail@univ-lorraine.fr\n\nmodule purge\nmodule load gcc/7.1.0\n\n## Creating temporary directory in $SCRATCHDIR\nWORKDIR=$SCRATCHDIR/job.$SLURM_JOB_ID.$USER\nmkdir -p $WORKDIR\n\n## Copying files to $WORKDIR \ncp -rf input executable  $WORKDIR\n\n## Moving to $WORKDIR\ncd $WORKDIR\n## Calculation\nsrun executable &lt; input\n\n## Copying back files to submit directory\ncp -rf * $SLURM_SUBMIT_DIR/.\n</code></pre>"},{"location":"slurm/#exemple-calcul-de-8-jours-et-30-min-avec-openmp-sur-8-curs","title":"Exemple : calcul de 8 jours et 30 min avec OpenMP sur 8 c\u0153urs","text":"<pre><code>#!/bin/bash\n#SBATCH -N 1  \n#SBATCH -p std\n#SBATCH -J openmp\n## Nombre de cpu par tache\n#SBATCH -c 8\n#SBATCH -t 8-00:30:00\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=votremail@univ-lorraine.fr\n\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\nmodule purge\nmodule load intel/2018.0.128 mkl/2018.0.128\n\n\n## Creating temporary directory in $SCRATCHDIR\nWORKDIR=$SCRATCHDIR/job.$SLURM_JOB_ID.$USER\nmkdir -p $WORKDIR\n\n## Copying files to $WORKDIR \ncp -rf input executable  $WORKDIR\n\n## Moving to $WORKDIR\ncd $WORKDIR\n## Calculation\nsrun executable &lt; input\n\n## Copying back files to submit directory\ncp -rf * $SLURM_SUBMIT_DIR/.\n</code></pre>"},{"location":"slurm/#exemple-calcul-de-15-jours-et-3-heures-avec-mpi-sur-2-nuds-32-curs-chacun-sur-nuds-std","title":"Exemple : calcul de 15 jours et 3 heures avec MPI sur 2 n\u0153uds, 32 c\u0153urs chacun sur n\u0153uds std","text":"<pre><code>#!/bin/bash\n\n#SBATCH -N 2  \n#SBATCH -p std\n#SBATCH -J mpi\n## Nombre de taches demand\u00e9s\n#SBATCH -n 64 \n## Nombre de taches demand\u00e9s par n\u0153ud\n#SBATCH --ntasks-per-node=32\n#SBATCH -t 15-03\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=votremail@univ-lorraine.fr\n\nmodule purge\nmodule load intel/2018.0.128  intelmpi/2018.0.128 mkl/2018.0.128\n\n## Creating temporary directory in $SCRATCHDIR\nWORKDIR=$SCRATCHDIR/job.$SLURM_JOB_ID.$USER\nmkdir -p $WORKDIR\n\n## Copying files to $WORKDIR \ncp -rf input executable  $WORKDIR\n\n## Moving to $WORKDIR\ncd $WORKDIR\n## Calculation\nsrun executable &lt; input\n\n## Copying back files to submit directory\ncp -rf * $SLURM_SUBMIT_DIR/.\n</code></pre>"},{"location":"slurm/#exemple-calcul-de-30min-openmp-mpi-sur-2x32-curs-sur-un-nud-std","title":"Exemple : Calcul de 30min OpenMP + MPI sur 2x32 c\u0153urs sur un n\u0153ud std","text":"<pre><code>#!/bin/bash\n#SBATCH -N 2  \n#SBATCH -p std\n#SBATCH -J openmp\n#SBATCH --ntasks-per-node=1\n#SBATCH -c 32\n#SBATCH -t 30:00\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=votremail@univ-lorraine.fr\n\nmodule purge\nmodule load intel/2018.0.128  intelmpi/2018.0.128 mkl/2018.0.128\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n\n## Creating temporary directory in $SCRATCHDIR\nWORKDIR=$SCRATCHDIR/job.$SLURM_JOB_ID.$USER\nmkdir -p $WORKDIR\n\n## Copying files to $WORKDIR \ncp -rf input executable  $WORKDIR\n\n## Moving to $WORKDIR\ncd $WORKDIR\n## Calculation\nsrun executable &lt; input\n\n## Copying back files to submit directory\ncp -rf * $SLURM_SUBMIT_DIR/.\n</code></pre>"},{"location":"slurm/#exemple-calcul-de-30min-mpi-sur-8-curs-et-deux-gpu-sur-un-nud-gpu","title":"Exemple : Calcul de 30min MPI sur 8 c\u0153urs et deux GPU sur un n\u0153ud gpu","text":"<pre><code>#!/bin/bash\n#SBATCH -N 1  \n#SBATCH -p gpu\n#SBATCH -J mpi+gpu\n#SBATCH -n 8\n#SBATCH --gres=gpu:2\n#SBATCH -t 30:00\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=votremail@univ-lorraine.fr\n\nmodule purge\nmodule load intel/2018.0.128  intelmpi/2018.0.128 mkl/2018.0.128 cuda/8.0\n\n\n## Creating temporary directory in $SCRATCHDIR\nWORKDIR=$SCRATCHDIR/job.$SLURM_JOB_ID.$USER\nmkdir -p $WORKDIR\n\n## Copying files to $WORKDIR \ncp -rf input executable  $WORKDIR\n\n## Moving to $WORKDIR\ncd $WORKDIR\n## Calculation\nsrun executable &lt; input\n\n## Copying back files to submit directory\ncp -rf * $SLURM_SUBMIT_DIR/.\n</code></pre> <p>Si vous souhaitez utiliser la commande mpirun \u00e0 la place de srun avec le module intelmpi il est n\u00e9cessaire de rajouter dans vos scripts de soumission la commande : unset I_MPI_PMI_LIBRARY</p>"},{"location":"slurm/#annulation-dun-job","title":"Annulation d'un job","text":"<p>Pour annuler un job soumis taper la commande <code>$ scancel #JOBID</code>, <code>#JOBID</code> \u00e9tant le num\u00e9ro du job.</p>"},{"location":"slurm/#reservation-interactive-dun-nud-de-calcul-pour-compilationdebogage","title":"R\u00e9servation interactive d'un n\u0153ud de calcul (pour compilation/d\u00e9bogage)","text":"<p>Nous conseillons de compiler vos codes sources sur les n\u0153ud de calcul afin de profiter de l'ensemble des optimisations et d'\u00e9viter de surcharger la frontale. </p> <p>Pour cela vous avez la possibilit\u00e9 de r\u00e9server un n\u0153ud et de vous y connecter en mode interactif.</p> <p>Ex : pour demander un n\u0153ud de la partition std pendant 1 heure taper  :</p> <pre><code>[****@vm-gce17 ~]$ salloc -N1 -p std -t 1:00:00 srun --pty bash\n</code></pre> <pre><code>****@cna01's password: \nLast login: Fri Apr 21 21:10:16 2017 from vm-gce17.prod.explor\n[****@cna01 ~]$ \n</code></pre> <p>Pour quitter le mode interactif, taper la commande <code>$ exit</code> :</p> <pre><code>[****@cna01 ~]$ exit\nlogout\nConnection to cna01 closed.\nsalloc: Job allocation 5232 has been revoked.\n</code></pre>"},{"location":"stockage/","title":"Espaces de Stockage","text":"<p>$HOMEDIR : Espace commun \u00e0 tous les utilisateurs d'un projet, y est inclus l'espace $SHAREDIR qui est un espace partag\u00e9 entre l'ensemble des utilisateurs d'un projet.</p> <p>$SAVEDIR : Espace de sauvegarde propre \u00e0 chaque utilisateur.</p> <p>$SCRATCHDIR : Espace de calcul temporaire utilis\u00e9 exclusivement pendant la dur\u00e9e de vos traitements, les donn\u00e9es seront automatiquement effac\u00e9es au bout de 30 jours ou avant si la gestion de l'espace le n\u00e9cessite. </p> <p>En attendant la mise en place d'un syst\u00e8me de fichier parall\u00e8le pr\u00e9vu pour d\u00e9but 2018, le $SCRATCHDIR est un r\u00e9pertoire local aux n\u0153uds de calcul.  Les donn\u00e9es pr\u00e9sentes dans cet espace ne sont pas accessibles depuis l'espace utilisateur. Assurez-vous donc de copier les r\u00e9sultats de vos jobs sur votre espace utilisateur $HOMEDIR  dans votre script de soumission slurm (voir exemples de scripts de soumission) . </p> Espace de Stockage Quota Espace Partag\u00e9 Soumission de jobs depuis cet espace Sauvegard\u00e9 Temporaire $HOMEDIR 1To extensible Non Oui (lent, d\u00e9conseill\u00e9) Non Non $SHAREDIR inclus dans le $HOMEDIR Oui (entre utilisateurs d'un projet) Oui (lent,d\u00e9conseill\u00e9) Non Non $SAVEDIR 10Go Non Non Oui Non $SCRATCHDIR 800Go Non Oui (rapide, conseill\u00e9) Non Oui"},{"location":"transfert/","title":"Transferts de fichiers","text":""},{"location":"transfert/#copie-de-fichiers-via-la-commande-scp","title":"Copie de fichiers via la commande scp","text":"<ul> <li> <p>Pour copier un dossier depuis votre poste de travail sur le r\u00e9pertoire courant de votre environnement de travail EXPLOR  si vous avez proc\u00e9d\u00e9 \u00e0 la cr\u00e9ation d'un alias ssh :</p> <p><code>$ scp -r &lt;dossier&gt; meso-explor:</code></p> </li> <li> <p>Sinon :</p> <p><code>$ scp -r -P xxxx  &lt;dossier&gt; votre_identifiant@193.54.9.82:</code></p> </li> </ul> <p>xxxx \u00e9tant votre port de connexion</p>"},{"location":"transfert/#synchronisation-dun-dossier-via-la-commande-rsync","title":"Synchronisation d'un dossier via la commande rsync","text":"<ul> <li> <p>Pour synchroniser un dossier depuis votre poste de travail sur le r\u00e9pertoire courant de votre environnement de travail EXPLOR :</p> <p><code>$ rsync -avzre \"ssh -p xxxx\" &lt;dossier&gt; votre_identifiant@193.54.9.82:</code></p> </li> </ul> <p>xxxx \u00e9tant votre port de connexion</p>"},{"location":"transfert/#partage-de-dossier-avec-x2go","title":"Partage de dossier avec X2GO","text":"<p>X2GO permet le partage en lecture/\u00e9criture d'un r\u00e9pertoire de votre poste de travail personnel sur votre environnement de travail EXPLOR. Pour activer cette fonctionnalit\u00e9 veuillez suivre les instructions ci-dessous :</p> <ul> <li>Dans \"Dossier Partag\u00e9s\", ajouter les dossiers que vous souhaitez partager et cocher les options (Monter automatiquement, Tunnel SSH...) comme ci-dessous :</li> </ul> <p></p> <ul> <li>\u00c0 la prochaine connexion, les dossiers partag\u00e9s sont accessibles dans $HOMEDIR/media/disk</li> </ul> <p></p> <p>Un bug courant de X2GO est de ne pouvoir partager les r\u00e9pertoires contenant des accents ou caract\u00e8res non conventionnels.</p> <p>Il n'est pas autoris\u00e9 de soumettre des jobs slurm depuis un dossier partag\u00e9</p>"}]}